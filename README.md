# LanCOPE
This is the implementation code of LanCOPE. The details will be released after the paper is accepted.

## Installation
Our code has been trained and tested with:
- Ubuntu 20.04
- Python 3.8.15
- PyTorch 1.12.0
- CUDA 11.3


## Datasets
Download the [NOCS](https://github.com/hughw19/NOCS_CVPR2019) dataset ([camera_train](http://download.cs.stanford.edu/orion/nocs/camera_train.zip), [camera_test](http://download.cs.stanford.edu/orion/nocs/camera_val25K.zip), [camera_composed_depths](http://download.cs.stanford.edu/orion/nocs/camera_composed_depth.zip), [real_train](http://download.cs.stanford.edu/orion/nocs/real_train.zip), [real_test](http://download.cs.stanford.edu/orion/nocs/real_test.zip),
[ground truths](http://download.cs.stanford.edu/orion/nocs/gts.zip), [mesh models](http://download.cs.stanford.edu/orion/nocs/obj_models.zip), and [segmentation results](https://drive.google.com/file/d/1hNmNRr7YRCgg-c_qdvaIzKEd2g4Kac3w/view?usp=sharing)) and Wild6D ([testset](https://ucsdcloud-my.sharepoint.com/:u:/r/personal/yafu_ucsd_edu/Documents/Wild6D/test_set.zip)). Data processing can refer to [IST-Net](https://github.com/CVMI-Lab/IST-Net). Unzip and organize these files in ../data as follows:
```
data
├── CAMERA
├── camera_full_depths
├── Real
├── gts
├── obj_models
├── segmentation_results
├── Wild6D
```
We provide the [real_test](https://drive.google.com/drive/folders/1Vt2ejrx-qymPv0KOENEDdnOkXabmyF_U?usp=sharing) dataset generated by [MonoDiff9D](https://github.com/CNJianLiu/MonoDiff9D). Other datasets can be generated easily based on the "../tools/depth_recovery.py" file.


## Training
To train the model, remember to download the complete datasets and organize & preprocess them properly.

train.py is the main file for training. You can start training using the following command:
```
python train.py --gpus 0 --config config/rgb_diffusion_pose.yaml
```
